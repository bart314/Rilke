{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://deepset.ai/german-word-embeddings\n",
    "https://www.analyticsvidhya.com/blog/2020/03/pretrained-word-embeddings-nlp/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Bidirectional,Dropout\n",
    "\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: \n",
    "# tokenize the corpus\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "data = ''\n",
    "for i in range(1,11):\n",
    "    data += open(f'data/el{i}.txt','r').read()\n",
    "    \n",
    "corpus = data.split('\\n')\n",
    "\n",
    "# we slaan de tokenizer ook op, omdat we die in een volgende\n",
    "# stap weer nodig hebben\n",
    "tokenizer.fit_on_texts(corpus) \n",
    "with open ('files/tokenizer.pkl', 'wb') as f:\n",
    "    pkl.dump(tokenizer, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total of different words in the corpus is 2287\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: \n",
    "# create a dictionary of words \n",
    "# key-value pair, key => word, value => token for that word\n",
    "\n",
    "total_words = len(tokenizer.word_index) + 1 # for OOV token\n",
    "print (f'The total of different words in the corpus is {total_words}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================\n",
      "Generating input-sequences\n",
      "The length of the input_sequence is 5683\n"
     ]
    }
   ],
   "source": [
    "# STEP 3:\n",
    "# Generating the training data\n",
    "\n",
    "print ('=================')\n",
    "print ('Generating input-sequences')\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    #list of the token representing the words\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\n",
    "    # first two words, first three words, first four words, ...\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "print (f'The length of the input_sequence is {len(input_sequences)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the length of the longest sentence in the corpus\n",
      "The longest sentence in the corpus is 13 words.\n"
     ]
    }
   ],
   "source": [
    "# STEP 5:\n",
    "# Find the largest sentence in the corpus and \n",
    "# pad all the other sentences to this length\n",
    "\n",
    "# find the length of the longest sentence in the corpus\n",
    "print ('Finding the length of the longest sentence in the corpus')\n",
    "max_sequence_length = max([len(x) for x in input_sequences])\n",
    "print (f'The longest sentence in the corpus is {max_sequence_length } words.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5683, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pad all the sequences so that they are the same length\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')) \n",
    "#padded input sequences\n",
    "\n",
    "#turn them into vectors of x's and y's, input values and their labels...\n",
    "#last character is the label, first n characters are the x's\n",
    "\n",
    "input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6:\n",
    "# Creating train and validation data-sets and\n",
    "# making X-matrices and y-vector\n",
    "m,n = input_sequences.shape \n",
    "data_train, data_cv = input_sequences[:int(m*.8)], input_sequences[int(m*.8):]\n",
    "X_train, X_cv = data_train[:,:-1], data_cv[:,:-1]\n",
    "labels_train, labels_cv = data_train[:,-1], data_cv[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7:\n",
    "# one-hot encode the labels\n",
    "ys_train = tf.keras.utils.to_categorical(labels_train, num_classes=total_words)\n",
    "ys_cv = tf.keras.utils.to_categorical(labels_cv, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 8:\n",
    "# Create a model in order to\n",
    "# find out what the next word should be\n",
    "model = Sequential() \n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_length - 1))\n",
    "#model.add(Bidirectional(LSTM(200)))\n",
    "#model.add(Dropout(.2))\n",
    "model.add(LSTM(500))\n",
    "\n",
    "# One neuron per word, which will light up if that is the predicted word\n",
    "model.add(Dense(total_words, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 12, 64)            146368    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 200)               212000    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2287)              459687    \n",
      "=================================================================\n",
      "Total params: 818,055\n",
      "Trainable params: 818,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Het daadwerkelijke trainen van het model duurt te lang voor deze demonstratie\n",
    "# dus ik laad even een versie die al getraind is.\n",
    "\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "# hist = model.fit(X_train, ys_train, epochs=250, validation_data=[X_cv, ys_cv])\n",
    "# print (\"=== [SAVE HISTORY] =====\")\n",
    "# with open('history.pkl', 'wb') as file_pi:\n",
    "#     pkl.dump(hist.history, file_pi)\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('files/rilke_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wer zeigt ein kind so wie es steht wer stellt will war er ists wieder so blieb sie doch nur mir einmal ich in den andern bezug sei sei das früchte was dir dir weiter daß nie nicht hörte mich doch an alles ist der engel schielaug nackens er grade herzens rief wo er im herzen – über er leise konnte leise mehr – mehr neue seltsam die leere welt dir sich läßt menschen und er so mehr furchtbar neue an der engel wäre ihm er nicht schreiten daß es nicht weil die engel o an an wenig großsein furchtbar dorten\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict the next 100 words\n",
    "\n",
    "line = 'Wer'\n",
    "for _ in range(100):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
    "    #predicted = model.predict_classes(token_list, verbose=0)\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = ''\n",
    "\n",
    "    #reverse look-up\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    line += ' ' + output_word\n",
    "line += \"\\n\"\n",
    "print (line) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pred-ana",
   "language": "python",
   "name": "predictive-analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
